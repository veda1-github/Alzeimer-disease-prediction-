{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QSE8kGpHQ_u8"
   },
   "outputs": [],
   "source": [
    "#Commands to access the datasets on Kaggle\n",
    "#Make a seperate directory for kaggle and give access for Kaggle to export datasets\n",
    "! mkdir ~/.kaggle\n",
    "! cp kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ze4DZ7jlRP8Q",
    "outputId": "cee61e53-97e5-4c98-b40d-b916feb759e8"
   },
   "outputs": [],
   "source": [
    "#Download the dataset\n",
    "!kaggle datasets download -d uraninjo/augmented-alzheimer-mri-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjNVGIuCUzT5"
   },
   "source": [
    "The datasets consists only images, which are divided into four categories, namely:\n",
    "1. Very MildDemented\n",
    "2. Mild Demented\n",
    "3. Moderate Demented\n",
    "4. Non-Demented\n",
    "\n",
    "The dataset is currently downloaded in a zipfile format. Unzip the folder to access the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "1L0scLnuRSid"
   },
   "outputs": [],
   "source": [
    "#Unzipping the zipfile of images\n",
    "import zipfile\n",
    "\n",
    "data_zip = zipfile.ZipFile('content/Alzheimer\\'s_dataset.zip')\n",
    "data_zip.extractall()\n",
    "data_zip.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emOymWk_V1D7"
   },
   "source": [
    "There are two folders in the datasets- One with original images and the other with augmented images.\n",
    "\n",
    "Seperate them by assigning them as testing and training, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3tcjzxH5XsAD",
    "outputId": "489b5a8f-7894-4fad-fac6-5ea27cc99e42"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'kaggle' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d pranavraikokte/covid19-image-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "IV3PekNQXwUj"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/covid19-image-dataset.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Unzipping the zipfile of images\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzipfile\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m data_zip \u001b[38;5;241m=\u001b[39m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/content/covid19-image-dataset.zip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m data_zip\u001b[38;5;241m.\u001b[39mextractall()\n\u001b[0;32m      6\u001b[0m data_zip\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\Program Files\\Python312\\Lib\\zipfile\\__init__.py:1323\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1323\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m   1325\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/covid19-image-dataset.zip'"
     ]
    }
   ],
   "source": [
    "#Unzipping the zipfile of images\n",
    "import zipfile\n",
    "\n",
    "data_zip = zipfile.ZipFile('/content/covid19-image-dataset.zip')\n",
    "data_zip.extractall()\n",
    "data_zip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hLGyAIUvRvp3"
   },
   "outputs": [],
   "source": [
    "#Create seperate directories for training and testing images.\n",
    "\n",
    "train_dir = '/content/AugmentedAlzheimerDataset/'\n",
    "test_dir = '/content/OriginalDataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "npa3QKdtSqDz"
   },
   "outputs": [],
   "source": [
    "#Import all the required libraries for data pre-processing and training.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOOO47XcWvUK"
   },
   "source": [
    "The images are further partitioned into training and validation images with 80% training and 20% validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f3l6i_0haKbY"
   },
   "outputs": [],
   "source": [
    "#Create instances of ImageDataGenerator by setting a rescale value and validation split.\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1/255. , validation_split = 0.2)\n",
    "test_datagen = ImageDataGenerator(rescale = 1/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wFHKbzXVd1ka",
    "outputId": "d05375b8-ab72-409d-8c39-ef33cea8d324"
   },
   "outputs": [],
   "source": [
    "train_data = train_datagen.flow_from_directory(train_dir ,\n",
    "                                               target_size = (224 , 224),    #Set image size.\n",
    "                                               batch_size = 32,              #Set appropriate batch size to avoid overfitting.\n",
    "                                               class_mode = 'categorical',   #Set type of labels.\n",
    "                                               subset = 'training')\n",
    "\n",
    "valid_data = train_datagen.flow_from_directory(train_dir,\n",
    "                                               target_size = (224 , 224),\n",
    "                                               batch_size = 32,\n",
    "                                               class_mode = 'categorical',\n",
    "                                               subset = 'validation')\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(test_dir,\n",
    "                                             target_size = (224 , 224),         #Images from the OriginalDataset directory to be used for testing only\n",
    "                                             batch_size = 32,\n",
    "                                             class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0e_qf5PYj051"
   },
   "outputs": [],
   "source": [
    "#Define a function to plot the loss and accuracy curves of model training for better visualization.\n",
    "\n",
    "def loss_and_accuracy(history):\n",
    "\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  accuracy = history.history['accuracy']\n",
    "  val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "  epochs = range(len(history.history['loss']))\n",
    "\n",
    "  plt.plot(epochs , loss , label = 'Training Loss')\n",
    "  plt.plot(epochs , val_loss , label = 'Validation Loss')            #Loss curve\n",
    "  plt.title('Loss Curve')\n",
    "  plt.xlabel('epochs')\n",
    "  plt.legend()\n",
    "  plt.savefig('Loss_Curve.jpg')\n",
    "\n",
    "  plt.figure()\n",
    "\n",
    "  plt.plot(epochs , accuracy , label = 'training_accuracy')\n",
    "  plt.plot(epochs , val_accuracy , label = 'validation_accuracy')    #Accuracy curve\n",
    "  plt.title('Accuracy Curve')\n",
    "  plt.yticks([0,0.2,0.4,0.6,0.8,1])\n",
    "  plt.xlabel('epochs')\n",
    "  plt.legend()\n",
    "  plt.savefig('Accuracy_Curve.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M-szW0c1t6Qe"
   },
   "outputs": [],
   "source": [
    "#Give the classnames as a list\n",
    "classnames = ['Mild Demented' , 'Moderate Demented' , 'Non-Demented' , 'Very Mild Demented']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y4yXfz8GooF8"
   },
   "outputs": [],
   "source": [
    "#Define a function to prepare an image for prediction\n",
    "\n",
    "def image_prep(filename , img_size = 224):\n",
    "  #Read the image from filename\n",
    "  image = tf.io.read_file(filename)\n",
    "  #Decode the image into its RGB channels\n",
    "  image = tf.image.decode_image(image , channels = 3)\n",
    "  #Resize the image\n",
    "  image = tf.image.resize(image , size = [img_size , img_size])\n",
    "  #Rescale\n",
    "  image = image/255.\n",
    "\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wc3KhKbQtxGf"
   },
   "outputs": [],
   "source": [
    "#Define a function to make predictions on the prepared images\n",
    "#Image along with the classified label is shown as output\n",
    "\n",
    "def make_predictions(model , filename , classnames):\n",
    "  #Load the image\n",
    "  image = image_prep(filename)\n",
    "  #Run the model on the image\n",
    "  pred = model.predict(tf.expand_dims(image , axis=0))\n",
    "  #Zero down on the class\n",
    "  pred_class = classnames[tf.argmax(tf.round(pred)[0])]\n",
    "  #Show the image and the label\n",
    "  plt.imshow(image)\n",
    "  plt.title(f'Predicted class: {pred_class}')\n",
    "  plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2oarYFXcEwF"
   },
   "outputs": [],
   "source": [
    "#Create an EarlyStopping callback method that stops training when accuracy does not improve.\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy' , patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cNNehQ-xhR-B"
   },
   "outputs": [],
   "source": [
    "model_1 = tf.keras.Sequential([\n",
    "    layers.Conv2D(128 , 2 , activation = 'relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Conv2D(128 , 2 , activation = 'relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(4 , activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JsK2g3FVhR6I"
   },
   "outputs": [],
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy',\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DlZ-ixdAhR2J"
   },
   "outputs": [],
   "source": [
    "history_1 = model_1.fit(train_data,\n",
    "                        epochs = 50,\n",
    "                        steps_per_epoch = int(0.1*len(train_data)),\n",
    "                        validation_data = valid_data,\n",
    "                        callbacks = [callback],\n",
    "                        verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "syAR0kv0kCPJ",
    "outputId": "ffac7114-4c74-49ed-dfcb-74e59c15a65f"
   },
   "outputs": [],
   "source": [
    "len(history_1.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KMxWXVgwkFzl",
    "outputId": "5ca07f3f-0605-4d23-f3ac-d922e21ef0c4"
   },
   "outputs": [],
   "source": [
    "model_1.evaluate(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "io5y4zjghf8R",
    "outputId": "20175727-66b4-43a6-9631-c56a3c090e45"
   },
   "outputs": [],
   "source": [
    "loss_and_accuracy(history = history_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "Chlb60w3hf4i",
    "outputId": "7ec47211-161c-4769-ab9e-55ccfd7cbf3e"
   },
   "outputs": [],
   "source": [
    "make_predictions(model_1 , '/content/OriginalDataset/VeryMildDemented/26 (45).jpg' , classnames )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
